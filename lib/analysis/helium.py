# -*- coding: utf-8 -*-
"""helium_interactive_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OzmjNUilRZIR_7U1n44mrTwdBzYVirZX

### **Installing packages, importing libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import io
import re
from google.colab import files
from typing import Optional, Dict, List
import matplotlib.font_manager as fm

# 1. Download the font file from Google Fonts
font_url = 'https://github.com/google/fonts/raw/main/ofl/poppins/Poppins-Regular.ttf'
font_path = 'Poppins-Regular.ttf'

# Use wget to download quietly
os.system(f'wget -q -O {font_path} {font_url}')

# 2. Add the font to Matplotlib's font manager
fm.fontManager.addfont(font_path)

# 3. Set Poppins as the default font for all plots
# Matplotlib will now find 'Poppins' in its list of available fonts.
plt.rc('font', family='Poppins')

"""### **Defining upload functions**"""

def handle_file_upload(uploaded_file_dict: Dict[str, bytes]) -> Optional[pd.DataFrame]:
  """ Check a single CSV file is uploaded and return it as a DataFrame. """

  # 1. Check if a single file was uploaded
  if not uploaded_file_dict:
    print(f"❌ Error: No file uploaded. Run the cell again and select a file.")
    return None

  if len(uploaded_file_dict) > 1:
    print(f"❌ Error: Upload only one file. You uploaded {len(uploaded_file_dict)} files.")
    return None

  file_name = list(uploaded_file_dict.keys())[0]
  file_content = uploaded_file_dict[file_name]

  # 2. Check if the file is a CSV
  if not file_name.lower().endswith('.csv'):
    _, extension = os.path.splitext(file_name)
    if extension:
      print(f"❌ Error: Uploaded file must be a CSV. You uploaded a '{extension}' file.")
    else:
      print(f"❌ Error: Uploaded file must be a CSV. The uploaded file '{file_name}' has no extension.")
    return None

  # 3. Check if file can be read into DF
  try:
    df = pd.read_csv(io.BytesIO(file_content))
    return df
  except Exception as e:
    print(f"❌ Error: Could not read the CSV file. Please ensure it's correctly formatted.\nDetails: {e}")
    return None

def validate_df_structure(df: pd.DataFrame) -> bool:
  """ Validate CSV matches expected structure. """

  # 1. Validate DF structure (6 rows, a 'Metric' column, >= 3 date columns)
  error_messages: List[str] = []
  if len(df) != 6:
    error_messages.append(f"File must have exactly 6 rows, but it has {len(df)}.")

  if 'Metric' not in df.columns:
    error_messages.append(f"File is missing the required 'Metric' column.")

  date_columns = [col for col in df.columns if re.match(r'^\d{4}-\d{2}-\d{2}$', col)]
  if len(date_columns) < 3:
    error_messages.append(f"File must have at least 3 date columns in format '2024-05-31', but found {len(date_columns)}.")

  if error_messages:
    print("❌ Error: File content invalid. Check CSV structure.")
    for msg in error_messages:
      print(f"- {msg}")
    return False

  # 2. Validate 'Metric' column content specifically
  required_metrics = {
      'organic traffic',
      'organic keywords',
      'organic traffic cost',
      'paid traffic',
      'paid keywords',
      'paid traffic cost'
  }

  if not pd.api.types.is_string_dtype(df['Metric']) and not pd.api.types.is_object_dtype(df['Metric']):
    print(f"❌ Error: 'Metric' column must contain text/string data.")
    return False

  metric_values_in_file = set(df['Metric'].str.lower())
  if metric_values_in_file != required_metrics:
    print("❌ Error: The 'Metric' column contains incorrect or missing values.")
    missing = required_metrics - metric_values_in_file
    extra = metric_values_in_file - required_metrics
    if missing:
      print(f"- The following required metrics are missing: {', '.join(missing)}")
    if extra:
      print(f"- The following values are not valid metrics: {', '.join(extra)}")
    return False

  # 3. Validate data types of date columns
  non_integer_date_cols: List[str] = []
  for col in date_columns:
    if not pd.api.types.is_integer_dtype(df[col]):
      non_integer_date_cols.append(col)

  if non_integer_date_cols:
    print("❌ Error: Some date columns do not contain only integers.")
    print(f"- The following columns have non-integer values: {', '.join(non_integer_date_cols)}")
    return False

  # 4. Return True if DataFrame successfully validated without errors
  print("✅ Success! The DataFrame structure and content have been validated.")
  return True

"""### **Upload File**

Upload a CSV file that matches the structure and format shown below.
* **5 Static Columns**: *Target*, *Target Type*, *Metric*, *Database*, *Summary* .
* **Date Columns**: 3 or more columns in the format `YYYY-MM-DD`, containing only integer values.
<br><br>

*Metric* column must contain these values (in any order):
* `Organic Traffic`
* `Organic Keywords`
* `Organic Traffic Cost`
* `Paid Traffic`
* `Paid Keywords`
* `Paid Traffic Cost`
<br><br>

**Example CSV file**

| Target            | Target Type | Metric               | Database | Summary | 2023-06-17 | 2023-06-18 | ... | 2025-06-11 |
| :---------------- | :---------- | :------------------- | :------- | :------ | :--------- | :--------- | :-- | :--------- |
| clientwebsite.com | root domain | Organic Traffic      | us       | 24827   | 80         | 85         | ... | 83         |
| clientwebsite.com | root domain | Organic Keywords     | us       | 56346   | 210        | 205        | ... | 207        |
| clientwebsite.com | root domain | Organic Traffic Cost | us       | 30452   | 130        | 125        | ... | 127        |
| clientwebsite.com | root domain | Paid Traffic         | us       | 738     | 6          | 5          | ... | 5          |
| clientwebsite.com | root domain | Paid Keywords        | us       | 978     | 5          | 4          | ... | 4          |
| clientwebsite.com | root domain | Paid Traffic Cost    | us       | 958     | 5          | 4          | ... | 4          |
"""

raw_df: Optional[pd.DataFrame] = None
while raw_df is None:
  uploaded = files.upload()
  df = handle_file_upload(uploaded)

  if df is None:
    print(f"\nTry again!")
  else:
    if not validate_df_structure(df):
      print(f"\nTry again!")
    else:
      raw_df = df

raw_df.head(10)

"""### **Drop redundant or empty columns**"""

dropping_cols = ['Target', 'Target Type', 'Database', 'Summary']
cleaned_df = raw_df.drop(dropping_cols, axis=1)

cleaned_df['Metric'] = cleaned_df['Metric'].astype('string')

# Remove columns where all values are 0 or NaN
cleaned_df = cleaned_df.loc[:, (df != 0).any()]  # Remove columns where all values are 0
cleaned_df = cleaned_df.dropna(axis=1, how='all')  # Remove columns where all values are NaN

"""### **Pivot table**"""

melted_df = cleaned_df.melt(
    id_vars='Metric',
    value_vars=None,
    var_name='Date',
    value_name='Value'
)

melted_df['Date'] = pd.to_datetime(melted_df['Date'])

pivoted_df = melted_df.pivot_table(
    values='Value',
    index='Date',
    columns='Metric',
    aggfunc='first'
)

pivoted_df.columns.name = None

column_order = [
    'Organic Traffic',
    'Organic Keywords',
    'Organic Traffic Cost',
    'Paid Traffic',
    'Paid Keywords',
    'Paid Traffic Cost'
]

pivoted_df = pivoted_df[column_order]

# Show first 10 rows of pivoted table
pivoted_df.head(10)

# Show last 10 rows of pivoted table
pivoted_df.tail(10)

"""### **Filter DataFrame by date**"""

def filter_df(df, start_date=None, end_date=None):
  if not isinstance(df.index, pd.DatetimeIndex):
    raise TypeError("DF index is not a DatetimeIndex. Ensure data has been pivoted.")

  try:
    if start_date:
      pd.to_datetime(start_date)
    if end_date:
      pd.to_datetime(end_date)
  except ValueError as e:
    raise ValueError(f"Invalid date arguments.\nDetails: {e}")

  return df.loc[start_date:end_date]

end_date = pivoted_df.index.max()
start_date = end_date - pd.DateOffset(years=1)

# Filtering DF to most recent year of data
filtered_df = filter_df(pivoted_df, start_date, end_date)

filtered_df.head(10)

filtered_df.tail(10)

"""### **Aggregate by month**"""

df_monthly = filtered_df.resample('ME').sum()

df_monthly.head(10)

"""### **Setting brand colours**"""

PRIMARY = '#001330'      # (navy)
ACCENT = '#E6475F'       # (red)
SECONDARY = '#1A2C5A'    # (blue)
TERTIARY = '#ADC0ED'     # (light blue)
BACKGROUND = '#EFF2FB'   # (pale blue)

"""### **Organic Traffic vs Organic Keywords**"""

def create_dual_axis_plot(df, y1_metric, y2_metric, title, figsize=(12, 6)):
  """
  Create a dual-axis line plot comparing two metrics over time.

  Args:
    df: DataFrame with datetime index
    y1_metric: String name of first metric to plot (primary y-axis)
    y2_metric: String name of second metric to plot (secondary y-axis)
    title: Plot title
    figsize: Tuple of (width, height) for figure size
  """

  # Create figure and axis objects with a single subplot
  fig, ax1 = plt.subplots(figsize=figsize)

  # Plot first metric on primary y-axis
  ax1.set_xlabel('Date')
  ax1.set_ylabel(y1_metric, color=PRIMARY)
  line1 = ax1.plot(df.index, df[y1_metric], color=PRIMARY, label=y1_metric)
  ax1.tick_params(axis='y', labelcolor=PRIMARY)

  # Create a second y-axis that shares the same x-axis
  ax2 = ax1.twinx()
  ax2.set_ylabel(y2_metric, color=ACCENT)
  line2 = ax2.plot(df.index, df[y2_metric], color=ACCENT, label=y2_metric)
  ax2.tick_params(axis='y', labelcolor=ACCENT)

  # Add legend
  lines = line1 + line2
  labels = [l.get_label() for l in lines]
  ax1.legend(lines, labels, loc='upper right')

  # Add title
  plt.title(title)

  # Set x-axis ticks to show every month
  ax1.set_xticks(df.index)
  ax1.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m'))

  # Rotate x-axis labels for better readability
  ax1.tick_params(axis='x', rotation=45)

  # Adjust layout to prevent label cutoff
  plt.tight_layout()

  return fig, ax1, ax2

create_dual_axis_plot(
    df=df_monthly,
    y1_metric='Organic Traffic',
    y2_metric='Organic Keywords',
    title='Organic Traffic vs Organic Keywords'
)

plt.show()

"""### **Paid Traffic, Paid Traffic Cost vs Paid Keywords**"""

def create_triple_line_plot(df, metrics, title, figsize=(12, 6)):
  """
  Create a single-axis line plot comparing three metrics over time.

  Args:
      df: DataFrame with datetime index
      metrics: List of three metric names to plot
      title: Plot title
      figsize: Tuple of (width, height) for figure size
  """

  # Create figure and axis objects
  fig, ax = plt.subplots(figsize=figsize)

  # Plot three metrics using different colors
  ax.plot(df.index, df[metrics[0]], color=PRIMARY, label=metrics[0])
  ax.plot(df.index, df[metrics[1]], color=ACCENT, label=metrics[1])
  ax.plot(df.index, df[metrics[2]], color=SECONDARY, label=metrics[2])

  # Set labels and title
  ax.set_xlabel('Date')
  ax.set_ylabel('Value')
  ax.set_title(title)

  # Set x-axis ticks to show every month
  ax.set_xticks(df.index)
  ax.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m'))
  ax.tick_params(axis='x', rotation=45)

  # Add legend
  ax.legend(loc='upper right')

  # Adjust layout to prevent label cutoff
  plt.tight_layout()

  return fig, ax

create_triple_line_plot(
    df=df_monthly,
    metrics=['Paid Traffic', 'Paid Traffic Cost', 'Paid Keywords'],
    title='Paid Traffic, Paid Traffic Cost vs Paid Keywords'
)

plt.show()